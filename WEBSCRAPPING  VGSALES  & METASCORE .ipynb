{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e34e84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pour effectuer correctement le scrapping nous aurons besoin de ces bibiliotéques : \n",
    "\n",
    "import re  #pour analyser les chaines de caractéres\n",
    "import requests, bs4 #requests pour interagir avec le Web #bs4 pour BeautifulSoup\n",
    "from requests import get #Pour atteindre envoyer une requete htpp \n",
    "from bs4 import BeautifulSoup #Pour scrapper le site avec les balises html\n",
    "from IPython.core.display import clear_output  #Pour nettoyer le contenu de la trame (requete http)\n",
    "from warnings import warn #controler les alertes\n",
    "from time import sleep     #pour suspendre le temps d'execution durant un temps donné\n",
    "from random import randint #pour renvoyer aléatoirement un entier\n",
    "from time import time      #pour affiner le controle des requetes avec le temps (en secondes)\n",
    "  from IPython.core.display import clear_output  #Pour nettoyer le contenu de la trame (requete http)\n",
    "#pour scrapper le site il est important qu'il identifie via la requete HTTP que ne nous sommes pas un robot\n",
    "#car cela peut bloquer l'acces au site via une requete http get\n",
    "\n",
    "#on rentre les information de notre machine qui seront dans la trame http\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko)Chrome/70.0.3538.77 Safari/537.36'}\n",
    "\n",
    "#nous allons parcourir 196 pages, mais ici on initailise à bcp plus car on eu un pb avec l'iteration de la boucle\n",
    "#et le nombre de pages donc on a décidé d'initialisé à plus en mettant un nombre assez large\n",
    "pages = [str(i) for i in range(0,10000,1)]\n",
    "#Listes des informations à prendre dans les pages nom,date de sortie, plateforme,metascore,userscore\n",
    "names = []\n",
    "release_dates = []\n",
    "platform= []\n",
    "meta_scores =[]\n",
    "user_scores = []\n",
    "#paramétrage de la boucle du monitoring afin de visualiser l'enchainement des requetes de la boucle\n",
    "#plus de 196 pages et 56000 jeux à prendre\n",
    "start_time = time()\n",
    "requests = 0\n",
    "\n",
    "#iteration de la boucle avec la liste page (0=>10000)\n",
    "for page in pages:\n",
    "    \n",
    "\n",
    "    #avec la fonction get on créer la requete http\n",
    "    game = get('https://www.metacritic.com/browse/games/score/metascore/all/all/filtered?page='+ page,headers = headers)\n",
    "    #pause dans la boucle de 8 à 20 secondes\n",
    "    sleep(randint(8,20))\n",
    "    #initialisition de la variable requetes et du temps d'execution pour l'affichage du monitoring\n",
    "    requests += 1\n",
    "    elapsed_time = time() - start_time\n",
    "    #affichage du monitoring\n",
    "    print('Request:{}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))\n",
    "    clear_output(wait = True)\n",
    "    #affihce un message d'alerte si au moins 200 requetes ne sont pas executer\n",
    "    if game.status_code != 200:\n",
    "        warn('Request: {}; Status code: {}'.format(requests,response.status_code))\n",
    "    #arrete la boucle à partir de plus de 196 requetes\n",
    "    if requests > 196:\n",
    "        warn('Number of requests was greater than expected.')\n",
    "        break\n",
    "    #analyser le contenu de la réponse de la requete http dans la variable game_soup \n",
    "    game_soup = BeautifulSoup(game.text, 'html.parser')\n",
    "    #trouve le tag majeur pour nos infos à recupérer\n",
    "    container = game_soup.find_all('td', class_ = 'clamp-summary-wrap')\n",
    "    #itération dans le majeur tag trouver\n",
    "    for con in container:\n",
    "        #scrape le nom du jeux\n",
    "        name = con.find('h3').text\n",
    "        names.append(name)\n",
    "        #scrape la date de sortie\n",
    "        release_date = con.select('div.clamp-details span')[2].text\n",
    "        release_dates.append(release_date)\n",
    "        #scrape la plateforme\n",
    "        plateforme = con.select('div.clamp-details span')[1].text.strip()\n",
    "        platform.append(plateforme)\n",
    "        #scrape metascore\n",
    "        meta_score= con.select('a.metascore_anchor div')[0].text\n",
    "        meta_scores.append(meta_score)\n",
    "        #scrape user score\n",
    "        user_score = con.select('a.metascore_anchor div')[2].text\n",
    "        user_scores.append(user_score)\n",
    "        \n",
    "#sotck dans le df movie_df toutes les infos        \n",
    "import pandas as pd\n",
    "movie_df = pd.DataFrame({'Movie_names': names,\n",
    "'Release_dates': release_dates,\n",
    "'Platform': platform,\n",
    "'Meta_scores': meta_scores,\n",
    "'User_scores': user_scores})\n",
    "print(movie_df.info())\n",
    "\n",
    "\n",
    "#rename du nouveau dataframe pour hamrmoniser \n",
    "game_df = movie_df.rename(columns={\"Movie_names\": \"Name\", \"Release_dates\": \"Year\"})\n",
    "\n",
    "#convertion en format date \n",
    "game_df['Year'] = pd.to_datetime(game_df['Year'])\n",
    "#extraction de l'année avec la fonction year\n",
    "game_df['year'] = game_df['Year'].dt.year\n",
    "#extraction du df en un csv\n",
    "game_df.to_csv('metagames.csv')\n",
    "Jointure entre l'ancien Dataframe VGSALES et le nouveau DF avec les scores METAGAMES\n",
    "#telechargement du df vgsales.csv \n",
    "#telechargement du df metagames.csv\n",
    "\n",
    "metagames = pd.read_csv(\"/Users/walidbenghalia//PROJET VGSALES DATASCIENTEST/metagames.csv\")\n",
    "vgsales = pd.read_csv(\"~/Desktop/vgsales.csv\")\n",
    "display(vgsales)\n",
    "display(metagames)\n",
    "\n",
    "\n",
    "#comparaison des deux dataframe \n",
    "\n",
    "display(vgsales.head(1))\n",
    "display(metagames.head(1))\n",
    "\n",
    "#VGSALES : Traitement\n",
    "#remise à niveau du format year pour supprimer le .0\n",
    "\n",
    "#supprimer les NAN pour convertir en int \n",
    "#vgsales.dropna(inplace = True)\n",
    "\n",
    "\n",
    "#transfomation de Year en Int\n",
    "vgsales['year'] = vgsales['Year'].astype(int)\n",
    "vgsales\n",
    "\n",
    "#suppression de la colonne Year mauvaise\n",
    "vgsales = vgsales.drop(['Year'], axis=1)\n",
    "vgsales\n",
    "\n",
    "#metagames ; traitement\n",
    "\n",
    "metagames\n",
    "\n",
    "#suppression de Unnamed: 0 / Year\n",
    "\n",
    "metagames.drop(['Unnamed: 0','Year'],axis=1,inplace=True)\n",
    "display(metagames.head(1))\n",
    "display(vgsales.head(1))\n",
    "\n",
    "#stockage liste des valeurs unique Platform des deux dataFrame pour analyser les différences\n",
    "list_vgsales_plt = vgsales['Platform'].unique()\n",
    "display(list_vgsales_plt)\n",
    "\n",
    "list_metagames_plt = metagames['Platform'].unique()\n",
    "display(list_metagames_plt)\n",
    "\n",
    "#Changement des valeurs unique de platfrome de metagames avec celles de vgsales\n",
    "\n",
    "#On remplace les valeurs de metagames platform par celle de vgsales platform\n",
    "dictionnaire = {'Nintendo 64':'N64','PlayStation':'PS','PlayStation 3':'PS3','Dreamcast':'DC','Xbox 360':'X360',\n",
    "               'Wii':'Wii','Xbox One':'XOne','PC':'PC','PlayStation 2':'PS2','PlayStation 4':'PS4',\n",
    "               'GameCube':'GC','Xbox':'XB','Wii U':'WiiU','Game Boy Advance':'GBA','3DS':'3DS','DS':'DS',\n",
    "               'PlayStation Vita':'PSV','PSP':'PSP','Stadia':'SAT'}\n",
    "#remplacer les valeurs de metagames platform par le dictionnaire\n",
    "metagames['Platform'].replace(dictionnaire,inplace = True)\n",
    "\n",
    "#merge de metagames et vgsales\n",
    "vgsales_scores = metagames.merge(vgsales,on=['Name','year','Platform'],how='inner')\n",
    "#affiche les premiéres ligne du df merger vgsales_scores\n",
    "vgsales_scores\n",
    "\n",
    "vgsales_scores.info()\n",
    "\n",
    "#suppression des nan\n",
    "vgsales_scores.dropna(inplace=True)\n",
    "#dimension du df vgsales_scores\n",
    "vgsales_scores.shape\n",
    "(5932, 13)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
